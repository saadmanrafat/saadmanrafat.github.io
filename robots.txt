# robots.txt for saadman.dev
# Main directives
User-agent: *
Allow: /
Disallow: /search
Disallow: /assets/raw/
Disallow: /private/
Disallow: /cgi-bin/
Disallow: /temp/
Disallow: /draft/

# Google-specific crawlers
User-agent: Googlebot
Allow: /
Crawl-delay: 1

User-agent: Googlebot-Image
Allow: /assets/images/
Allow: /assets/images/blog/

# Bing-specific crawler
User-agent: Bingbot
Allow: /
Crawl-delay: 2

# Prevent crawling of specific file types
Disallow: /*.pdf$
Disallow: /*.doc$
Disallow: /*.docx$
Disallow: /*.zip$
Disallow: /*.tar$
Disallow: /*.gz$

# Prevent crawling of any backend routes
Disallow: /api/

# Prevent parameter-based URLs
Disallow: /*?*

# Sitemap declaration
Sitemap: https://saadman.dev/sitemap.xml

# RSS feed for blog
Sitemap: https://saadman.dev/rss.xml

# Host directive (recommended by Google)
Host: saadman.dev