# robots.txt for saadman.dev
# Main directives
User-agent: *
Allow: /
Disallow: /assets/raw/
Disallow: /private/
Disallow: /cgi-bin/
Disallow: /temp/
Disallow: /draft/
Disallow: /api/
Disallow: /.git/
Disallow: /.github/

# Prevent crawling of specific file types
Disallow: /*.pdf$
Disallow: /*.doc$
Disallow: /*.docx$
Disallow: /*.zip$
Disallow: /*.tar$
Disallow: /*.gz$

# Allow search engines to index search page
Allow: /search/

# Google-specific crawlers
User-agent: Googlebot
Allow: /
Crawl-delay: 1

User-agent: Googlebot-Image
Allow: /assets/images/
Allow: /assets/images/blog/

# Bing-specific crawler
User-agent: Bingbot
Allow: /
Crawl-delay: 2

# Sitemap declaration
Sitemap: https://saadman.dev/sitemap.xml

# RSS feed for blog
Sitemap: https://saadman.dev/rss.xml

# Host directive (recommended by Google)
Host: saadman.dev